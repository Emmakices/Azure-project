{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "file_path = \"abfss://raw-data@icezydatalake01.dfs.core.windows.net/raw-data/icezysales.csv\"\n",
        "\n",
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .csv(file_path)\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import col, lit, lower\n",
        "\n",
        "cleaned_df = df.fillna({\n",
        "    \"category_code\": \"unknown\",\n",
        "    \"brand\": \"unknown\",\n",
        "    \"price\": 0.0,\n",
        "})\n",
        "\n",
        "cleaned_df = cleaned_df.withColumn(\"event_type\", lower(col(\"event_type\"))) \\\n",
        "                       .withColumn(\"price\", col(\"price\").cast(\"double\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "session_activity = cleaned_df.groupBy(\"user_session\").agg(\n",
        "    count(\"*\").alias(\"events_in_session\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "event_spending = cleaned_df.groupBy(\"event_type\").agg(\n",
        "    sum(\"price\").alias(\"total_value\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "viewed_products = cleaned_df.filter(col(\"event_type\") == \"view\") \\\n",
        "    .groupBy(\"product_id\") \\\n",
        "    .count() \\\n",
        "    .orderBy(\"count\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "brand_sales = cleaned_df.filter(col(\"event_type\") == \"cart\") \\\n",
        "    .groupBy(\"brand\") \\\n",
        "    .agg(sum(\"price\").alias(\"total_cart_value\")) \\\n",
        "    .orderBy(\"total_cart_value\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "base_path = \"abfss://raw-data@icezydatalake01.dfs.core.windows.net/analytics_output/\"\n",
        "\n",
        "session_activity.write.mode(\"overwrite\").parquet(base_path + \"session_activity\")\n",
        "event_spending.write.mode(\"overwrite\").parquet(base_path + \"event_spending\")\n",
        "viewed_products.write.mode(\"overwrite\").parquet(base_path + \"viewed_products\")\n",
        "brand_sales.write.mode(\"overwrite\").parquet(base_path + \"brand_sales\")"
      ]
    }
  ]
}